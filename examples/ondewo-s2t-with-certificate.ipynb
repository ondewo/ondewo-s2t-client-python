{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Processing /home/jsteinbauer/ondewo/ondewo-s2t-client-python\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "Requirement already satisfied: grpcio==1.44.0 in /home/jsteinbauer/.conda/envs/ondewo_s2t_client/lib/python3.9/site-packages (from ondewo-s2t-client==3.1.2) (1.44.0)\n",
      "Requirement already satisfied: grpcio-reflection==1.44.0 in /home/jsteinbauer/.conda/envs/ondewo_s2t_client/lib/python3.9/site-packages (from ondewo-s2t-client==3.1.2) (1.44.0)\n",
      "Requirement already satisfied: grpcio-tools==1.44.0 in /home/jsteinbauer/.conda/envs/ondewo_s2t_client/lib/python3.9/site-packages (from ondewo-s2t-client==3.1.2) (1.44.0)\n",
      "Requirement already satisfied: mypy-protobuf==3.00 in /home/jsteinbauer/.conda/envs/ondewo_s2t_client/lib/python3.9/site-packages (from ondewo-s2t-client==3.1.2) (3.0.0)\n",
      "Requirement already satisfied: ondewo-client-utils>=0.1.0 in /home/jsteinbauer/.conda/envs/ondewo_s2t_client/lib/python3.9/site-packages (from ondewo-s2t-client==3.1.2) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5.2 in /home/jsteinbauer/.conda/envs/ondewo_s2t_client/lib/python3.9/site-packages (from grpcio==1.44.0->ondewo-s2t-client==3.1.2) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/jsteinbauer/.conda/envs/ondewo_s2t_client/lib/python3.9/site-packages (from grpcio-reflection==1.44.0->ondewo-s2t-client==3.1.2) (3.19.4)\n",
      "Requirement already satisfied: setuptools in /home/jsteinbauer/.conda/envs/ondewo_s2t_client/lib/python3.9/site-packages (from grpcio-tools==1.44.0->ondewo-s2t-client==3.1.2) (58.0.4)\n",
      "Requirement already satisfied: types-protobuf>=3.17.4 in /home/jsteinbauer/.conda/envs/ondewo_s2t_client/lib/python3.9/site-packages (from mypy-protobuf==3.00->ondewo-s2t-client==3.1.2) (3.19.15)\n",
      "Requirement already satisfied: regex==2020.7.14 in /home/jsteinbauer/.conda/envs/ondewo_s2t_client/lib/python3.9/site-packages (from ondewo-client-utils>=0.1.0->ondewo-s2t-client==3.1.2) (2020.7.14)\n",
      "Requirement already satisfied: dataclasses-json==0.5.2 in /home/jsteinbauer/.conda/envs/ondewo_s2t_client/lib/python3.9/site-packages (from ondewo-client-utils>=0.1.0->ondewo-s2t-client==3.1.2) (0.5.2)\n",
      "Requirement already satisfied: stringcase<2.0.0,==1.2.0 in /home/jsteinbauer/.conda/envs/ondewo_s2t_client/lib/python3.9/site-packages (from dataclasses-json==0.5.2->ondewo-client-utils>=0.1.0->ondewo-s2t-client==3.1.2) (1.2.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/jsteinbauer/.conda/envs/ondewo_s2t_client/lib/python3.9/site-packages (from dataclasses-json==0.5.2->ondewo-client-utils>=0.1.0->ondewo-s2t-client==3.1.2) (1.5.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/jsteinbauer/.conda/envs/ondewo_s2t_client/lib/python3.9/site-packages (from dataclasses-json==0.5.2->ondewo-client-utils>=0.1.0->ondewo-s2t-client==3.1.2) (3.15.0)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/jsteinbauer/.conda/envs/ondewo_s2t_client/lib/python3.9/site-packages (from dataclasses-json==0.5.2->ondewo-client-utils>=0.1.0->ondewo-s2t-client==3.1.2) (0.7.1)\n",
      "Requirement already satisfied: packaging in /home/jsteinbauer/.conda/envs/ondewo_s2t_client/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json==0.5.2->ondewo-client-utils>=0.1.0->ondewo-s2t-client==3.1.2) (21.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/jsteinbauer/.conda/envs/ondewo_s2t_client/lib/python3.9/site-packages (from typing-inspect>=0.4.0->dataclasses-json==0.5.2->ondewo-client-utils>=0.1.0->ondewo-s2t-client==3.1.2) (0.4.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/jsteinbauer/.conda/envs/ondewo_s2t_client/lib/python3.9/site-packages (from typing-inspect>=0.4.0->dataclasses-json==0.5.2->ondewo-client-utils>=0.1.0->ondewo-s2t-client==3.1.2) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/jsteinbauer/.conda/envs/ondewo_s2t_client/lib/python3.9/site-packages (from packaging->marshmallow<4.0.0,>=3.3.0->dataclasses-json==0.5.2->ondewo-client-utils>=0.1.0->ondewo-s2t-client==3.1.2) (3.0.7)\n",
      "Building wheels for collected packages: ondewo-s2t-client\n",
      "  Building wheel for ondewo-s2t-client (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ondewo-s2t-client: filename=ondewo_s2t_client-3.1.2-py2.py3-none-any.whl size=15885 sha256=58abdc2a8b7f2be9537fdadfb2f7de495684af739db287af1302ecc209424552\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-43u_iqo_/wheels/f6/25/2e/e0b74f28025bf203e07033a9f49a21907b7e6f00294cbabb97\n",
      "Successfully built ondewo-s2t-client\n",
      "Installing collected packages: ondewo-s2t-client\n",
      "Successfully installed ondewo-s2t-client-3.1.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "! cd .. && python -m pip install --user ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1634234935903,
     "user": {
      "displayName": "Andreas Rath",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjzXdeqp2hxSIMkaDT5PP1Srh8ARQRU8xQsUZeo=s64",
      "userId": "17066140692478356993"
     },
     "user_tz": -120
    },
    "id": "bcff103f"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import wave\n",
    "\n",
    "from ondewo.s2t import speech_to_text_pb2\n",
    "from ondewo.s2t.client.client import Client\n",
    "from ondewo.s2t.client.client_config import ClientConfig\n",
    "from ondewo.s2t.client.services.speech_to_text import Speech2Text\n",
    "from ondewo.s2t.speech_to_text_pb2 import ListS2tPipelinesRequest, Speech2TextConfig\n",
    "from ondewo.s2t.speech_to_text_pb2 import S2tPipelineId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a client object\n",
    "The example below shows how to create a speech to text client object from a client config. \n",
    "When setting *use_secure_channel=True*, a grpc certificate *grpc_cert* is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1634234935904,
     "user": {
      "displayName": "Andreas Rath",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjzXdeqp2hxSIMkaDT5PP1Srh8ARQRU8xQsUZeo=s64",
      "userId": "17066140692478356993"
     },
     "user_tz": -120
    },
    "id": "585c9e11",
    "outputId": "a032016c-49e1-46c3-bdb9-0187ce8fe72c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Using insecure grpc channel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClientConfig(host='dgxstation', port='50657', grpc_cert=None)\n"
     ]
    }
   ],
   "source": [
    "AUDIO_FILE: str = \"examples/audiofiles/sample_1.wav\"\n",
    "# credentials = grpc.ssl_channel_credentials(root_certificates=cert)\n",
    "\n",
    "MAX_MESSAGE_LENGTH: int = 60000000\n",
    "GRPC_HOST: str = \"dgxstation\"\n",
    "GRPC_PORT: str = \"50657\"\n",
    "CHANNEL: str = f\"{GRPC_HOST}:{GRPC_PORT}\"\n",
    "grpc_cert: str = None\n",
    "\n",
    "\n",
    "options = [\n",
    "    ('grpc.max_send_message_length', MAX_MESSAGE_LENGTH),\n",
    "    ('grpc.max_receive_message_length', MAX_MESSAGE_LENGTH),\n",
    "]\n",
    "\n",
    "# channel = grpc.secure_channel(CHANNEL, credentials, options=options)\n",
    "\n",
    "config: ClientConfig = ClientConfig(\n",
    "  host=GRPC_HOST,\n",
    "  port=GRPC_PORT, \n",
    "  grpc_cert=grpc_cert)\n",
    "    \n",
    "print(config)\n",
    "    \n",
    "client: Client = Client(config=config, use_secure_channel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List all existing speech to text pipelines\n",
    "All relevant configurations of the speech to text server are defined in a speech to text pipeline. \n",
    "A running server can store several such configs at the same time, such that the client can chose which one to \n",
    "pick when he sends a request to transcribe an audio file or stream.\n",
    "\n",
    "The example below shows how to list all available pipelines by calling the **s2t_service.list_s2t_pipelines()** function, which takes a **ListS2tPipelinesRequest()** as an argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 841,
     "status": "ok",
     "timestamp": 1634234936728,
     "user": {
      "displayName": "Andreas Rath",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjzXdeqp2hxSIMkaDT5PP1Srh8ARQRU8xQsUZeo=s64",
      "userId": "17066140692478356993"
     },
     "user_tz": -120
    },
    "id": "PT_wyVxIU8mk",
    "outputId": "72821027-e8c1-4732-d39a-383c78c20ec1",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: \"wav2vec_large_all_atc\"\n",
      "description {\n",
      "  language: \"en\"\n",
      "  pipeline_owner: \"ONDEWO\"\n",
      "  domain: \"atc\"\n",
      "}\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"wav2vec_triton\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet15x5_de_2/\"\n",
      "        step: \"837000\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/en/quartznet_czech_atc/QuartzNet15x5_czech_atc-last.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec_large_all_atc\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"all_atc.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"GREEDY\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 30.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"ato001\"\n",
      "description {\n",
      "  language: \"de\"\n",
      "  pipeline_owner: \"ondewo\"\n",
      "  domain: \"itsupport\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"wav2vec_triton\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/de/quartznet_telephone/quartznet_telephone.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet_telephone/\"\n",
      "        step: \"2500\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/de/ckpt_test/test.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/wav2vec2_large_1360h_telephonized/\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"german_lm_big.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"BEAM_SEARCH_WITH_LM\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 60.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  pipeline: \"normalization\"\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"wav2vec_large_czech_atc_augmented\"\n",
      "description {\n",
      "  language: \"en\"\n",
      "  pipeline_owner: \"ONDEWO\"\n",
      "  domain: \"atc\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"wav2vec_triton\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet15x5_de_2/\"\n",
      "        step: \"837000\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/en/quartznet_czech_atc/QuartzNet15x5_czech_atc-last.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec_large_cz_atc_augmented\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"all_atc.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"GREEDY\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 30.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"keb001\"\n",
      "description {\n",
      "  language: \"de\"\n",
      "  pipeline_owner: \"ondewo\"\n",
      "  domain: \"robotics\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"wav2vec_triton\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/de/quartznet_telephone/quartznet_telephone.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet_telephone/\"\n",
      "        step: \"2500\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/de/ckpt_test/test.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/wav2vec2_large_1360h_telephonized/\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"keba.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"BEAM_SEARCH_WITH_LM\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 60.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  pipeline: \"normalization\"\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"wav2vec_large_cz_atc\"\n",
      "description {\n",
      "  language: \"en\"\n",
      "  pipeline_owner: \"ONDEWO\"\n",
      "  domain: \"atc\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"wav2vec_triton\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet15x5_de_2/\"\n",
      "        step: \"837000\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/en/quartznet_czech_atc/QuartzNet15x5_czech_atc-last.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec_large_cz_atc\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"all_atc.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"GREEDY\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 30.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"wav2vec_base_all_atc\"\n",
      "description {\n",
      "  language: \"en\"\n",
      "  pipeline_owner: \"ONDEWO\"\n",
      "  domain: \"atc\"\n",
      "}\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"wav2vec_triton\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet15x5_de_2/\"\n",
      "        step: \"837000\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/en/quartznet_czech_atc/QuartzNet15x5_czech_atc-last.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec_base_all_atc\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"all_atc.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"GREEDY\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 30.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"general_english\"\n",
      "description {\n",
      "  language: \"en\"\n",
      "  pipeline_owner: \"ONDEWO\"\n",
      "  domain: \"general\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"wav2vec_triton\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet15x5_de_2/\"\n",
      "        step: \"837000\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/en/quartznet_czech_atc/QuartzNet15x5_czech_atc-last.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec_large_960h_lv60_self\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"all_atc.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"GREEDY\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 30.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 2\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"wav2vec_base_cz_atc\"\n",
      "description {\n",
      "  language: \"en\"\n",
      "  pipeline_owner: \"ONDEWO\"\n",
      "  domain: \"atc\"\n",
      "}\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"wav2vec_triton\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet15x5_de_2/\"\n",
      "        step: \"837000\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/en/quartznet_czech_atc/QuartzNet15x5_czech_atc-last.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec_base_cz_atc\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"all_atc.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"GREEDY\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 30.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s2t_service: Speech2Text = client.services.speech_to_text\n",
    "pipelines = s2t_service.list_s2t_pipelines(request=ListS2tPipelinesRequest()).pipeline_configs\n",
    "for pipeline in pipelines:\n",
    "    print(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1634234936731,
     "user": {
      "displayName": "Andreas Rath",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjzXdeqp2hxSIMkaDT5PP1Srh8ARQRU8xQsUZeo=s64",
      "userId": "17066140692478356993"
     },
     "user_tz": -120
    },
    "id": "IEMZ_gzlW4nK"
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "def find_pipeline_for_language(pipelines: List[Speech2TextConfig], language: str) -> Optional[Speech2TextConfig]:\n",
    "    \"\"\" \n",
    "    Returns the first speech to text pipeline for the requested language. \n",
    "    If no pipline is found, return None.\n",
    "    \"\"\"\n",
    "    for pipeline in pipelines:\n",
    "        if pipeline.description.language == language:\n",
    "            return pipeline\n",
    "\n",
    "english_pipeline = find_pipeline_for_language(pipelines=pipelines, language='en')\n",
    "german_pipeline = find_pipeline_for_language(pipelines=pipelines, language='de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "general_english\n",
      "wav2vec_base_all_atc\n",
      "wav2vec_base_cz_atc\n",
      "wav2vec_large_czech_atc_augmented\n",
      "wav2vec_large_all_atc\n",
      "wav2vec_large_cz_atc\n"
     ]
    }
   ],
   "source": [
    "for pipeline in pipelines:\n",
    "    if pipeline.description.language == 'en':\n",
    "        print(pipeline.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in example audio file\n",
    "This audio file will be used in the following transcription examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave \n",
    "\n",
    "audio_file_path = \"audiofiles/sample_1.wav\"\n",
    "\n",
    "with wave.open(audio_file_path) as w:\n",
    "    audio: bytes = w.readframes(w.getnframes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a transcribe file request to the server\n",
    "In general, are two different endpoints for audio transcriptions:\n",
    "1. **Transcribe an audio file** \n",
    "2. **Transcribe an audio stream**\n",
    "\n",
    "### Transcribe an audio file\n",
    "In this example, we create a **TranscribeFileRequest**, including the audio file (as bytes) and a **TranscribeRequestConfig** message, including the speech to text pipeline id, as well as optional additional parameters.\n",
    "The request message is then used as an argument to the **s2t_service.transcribe_file()**, which calls the corresponding endpoint.\n",
    "\n",
    "### TranscribeRequestConfig\n",
    "The TranscribeRequestConfig gives you maximal control in configuring the s2t server. \n",
    "\n",
    "It contains the following fields:\n",
    "\n",
    "1. **s2t_pipeline_id** (string): The pipeline id\n",
    "2. **ctc_decoding** (speech_to_text_pb2.CTCDecoding): The CTC decoding type - options are BEAM_SEARCH_WITH_LM, GREEDY\n",
    "3. **language_model_name** (string): The name of the language model\n",
    "4. **post_processing** (speech_to_text_pb2.PostProcessingOptions): Specifies options for post processing\n",
    "5. **utterance_detection** (speech_to_text_pb2.UtteranceDetectionOptions)\n",
    "6. **voice_activity_detection**: One of speech_to_text_pb2.Pyannote or speech_to_text_pb2.Matchbox\n",
    "7. **return_options** (speech_to_text_pb2.TranscriptionReturnOptions): The options on how to return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1055,
     "status": "ok",
     "timestamp": 1634234937777,
     "user": {
      "displayName": "Andreas Rath",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjzXdeqp2hxSIMkaDT5PP1Srh8ARQRU8xQsUZeo=s64",
      "userId": "17066140692478356993"
     },
     "user_tz": -120
    },
    "id": "34fe77f3",
    "outputId": "7221e03d-d89c-457d-a1f8-530c502302f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File transcript: hello i would like to order one large bitza with ham and cheese no mushrooms please \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "pipeline: Speech2TextConfig = english_pipeline\n",
    "\n",
    "request = speech_to_text_pb2.TranscribeFileRequest(\n",
    "    audio_file=audio,\n",
    "    config=speech_to_text_pb2.TranscribeRequestConfig(\n",
    "        s2t_pipeline_id=pipeline.id,\n",
    "        ctc_decoding=speech_to_text_pb2.CTCDecoding.GREEDY,\n",
    "    )\n",
    ")\n",
    "# Send transcription request and get response\n",
    "transcribe_response = s2t_service.transcribe_file(request=request)\n",
    "\n",
    "for transcription_message in transcribe_response.transcriptions:\n",
    "    print(f\"File transcript: {transcription_message.transcription}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe an audio stream\n",
    "In this example, we transcribe an audio stream by streaming a **TranscribeStreamRequest**, including audio chunks (as bytes) and a **TranscribeRequestConfig** message, including the speech to text pipeline id, as well as optional additional parameters.\n",
    "The request message generator is then used as an argument to the **s2t_service.transcribe_stream()**, which calls the corresponding endpoint.\n",
    "\n",
    "**Important**: After the TranscribeRequestConfig has been set once, it does not have to be sent with each new streameing request (this can help to save bandwidth). The old TranscribeRequestConfig remains until a new one is sent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1.: Transcribe full utterances only (default)\n",
    "In this mode, audio chunks are concatenated until a full utterance is accumulated (an utterance is considered \"finished\" if no voice is detected in the audio signal for `end_of_utterance_threshold` seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "from streaming_example import get_streaming_audio, create_streaming_request\n",
    "\n",
    "# Get audio stream (iterator of audio chunks)\n",
    "audio_stream: Iterator[bytes] = get_streaming_audio(\"audiofiles/sample_1.wav\")\n",
    "\n",
    "# Create streaming request\n",
    "streaming_request: Iterator[speech_to_text_pb2.TranscribeStreamRequest] = create_streaming_request(\n",
    "    audio_stream=audio_stream, \n",
    "    pipeline_id=pipeline.id,\n",
    "    transcribe_not_final=False,\n",
    ")\n",
    "\n",
    "# Transcribe the stream and get back responses\n",
    "response_gen: Iterator[speech_to_text_pb2.TranscribeStreamResponse] = s2t_service.transcribe_stream(\n",
    "    request_iterator=streaming_request\n",
    ")\n",
    "\n",
    "# Print transcribed utterances\n",
    "for i, response_chunk in enumerate(response_gen):\n",
    "    for transcribe_message in response_chunk.transcriptions:\n",
    "        print(f\"{i}. response_chunk: {transcribe_message.transcription}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1.: Transcribe not final\n",
    "In this mode, audio chunks are transcribed as soon as a minimal length of voice signal is accumulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "from streaming_example import get_streaming_audio, create_streaming_request\n",
    "\n",
    "# Get audio stream (iterator of audio chunks)\n",
    "audio_stream: Iterator[bytes] = get_streaming_audio(\"audiofiles/sample_1.wav\")\n",
    "\n",
    "# Create streaming request\n",
    "streaming_request: Iterator[speech_to_text_pb2.TranscribeStreamRequest] = create_streaming_request(\n",
    "    audio_stream=audio_stream, \n",
    "    pipeline_id=pipeline.id, \n",
    "    transcribe_not_final=True,\n",
    ")\n",
    "\n",
    "# Transcribe the stream and get back responses\n",
    "response_gen: Iterator[speech_to_text_pb2.TranscribeStreamResponse] = s2t_service.transcribe_stream(\n",
    "    request_iterator=streaming_request\n",
    ")\n",
    "\n",
    "# Print transcribed utterances\n",
    "for i, response_chunk in enumerate(response_gen):\n",
    "    for transcribe_message in response_chunk.transcriptions:\n",
    "        print(f\"{i}. response_chunk: {transcribe_message.transcription}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline CRUD\n",
    "In the following, we demonstrate how to do CRUD (Create, Retrieve, Update, Delete) pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GetS2TPipeline\n",
    "\n",
    "The example below shows how to get a pipeline by calling the **s2t_service.get_s2t_pipeline()** function, which takes a **S2tPipelineId** as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### GetS2TPipeline\n",
    "# To get a specific s2t pipeline, we can use the GetS2TPipeline endpoint.\n",
    "\n",
    "pipeline_id = 'quarznet_en'\n",
    "pipeline = s2t_service.get_s2t_pipeline(request=S2tPipelineId(id=pipeline_id))\n",
    "\n",
    "pipelines = s2t_service.list_s2t_pipelines(request=ListS2tPipelinesRequest(registered_only=True)).pipeline_configs\n",
    "print(f\"Number of pipelines: {len(pipelines)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeleteS2TPipeline\n",
    "\n",
    "The example below shows how to delete a pipeline by calling the **s2t_service.delete_s2t_pipeline()** function, which takes a **S2tPipelineId** as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### DeleteS2TPipeline\n",
    "# To delete specific s2t pipeline, we can use the GetS2TPipeline endpoint.\n",
    "\n",
    "deleted_pipeline = s2t_service.delete_s2t_pipeline(request=S2tPipelineId(id=pipeline_id))\n",
    "\n",
    "pipelines = s2t_service.list_s2t_pipelines(request=ListS2tPipelinesRequest(registered_only=True)).pipeline_configs\n",
    "print(f\"Number of pipelines after pipeline deletion: {len(pipelines)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CreateS2TPipeline\n",
    "\n",
    "The example below shows how to create a pipeline by calling the **s2t_service.create_s2t_pipeline()** function, which takes a **pipeline** as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ### CreateS2TPipeline\n",
    "# # To create specific s2t pipeline, we can use the CreateS2TPipeline endpoint.\n",
    "\n",
    "pipeline = s2t_service.create_s2t_pipeline(request=pipeline)\n",
    "\n",
    "pipelines = s2t_service.list_s2t_pipelines(request=ListS2tPipelinesRequest(registered_only=True)).pipeline_configs\n",
    "print(f\"Number of pipelines after pipeline creation: {len(pipelines)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ### UpdateS2TPipeline\n",
    "# # To update specific s2t pipeline, we can use the UpdateS2TPipeline endpoint.\n",
    "\n",
    "pipeline_id = 'quarznet_en'\n",
    "pipeline = s2t_service.get_s2t_pipeline(request=S2tPipelineId(id=pipeline_id))\n",
    "\n",
    "print(f\"Old end_of_utterance_threshold: {pipeline.streaming_server.streaming_speech_recognition.end_of_utterance_threshold}\")\n",
    "\n",
    "# Update the end_of_utterance_threshold\n",
    "pipeline.streaming_server.streaming_speech_recognition.end_of_utterance_threshold = 1.5\n",
    "s2t_service.update_s2t_pipeline(request=pipeline)\n",
    "\n",
    "new_pipeline = s2t_service.get_s2t_pipeline(request=S2tPipelineId(id=pipeline_id))\n",
    "\n",
    "print(f\"New end_of_utterance_threshold: {new_pipeline.streaming_server.streaming_speech_recognition.end_of_utterance_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ondewo-s2t-with-certificate.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "de2ed104cf3bee5ac5c3780eed171797f09568a0a669428569335bd376aa9e40"
  },
  "kernelspec": {
   "display_name": "florian_env",
   "language": "python",
   "name": "florian_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
