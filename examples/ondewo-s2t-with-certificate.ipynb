{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Processing /home/jsteinbauer/ondewo/ondewo-s2t-client-python\n",
      "Requirement already satisfied: grpcio==1.31.0 in /home/jsteinbauer/.local/lib/python3.8/site-packages (from ondewo-s2t-client==1.4.1) (1.31.0)\n",
      "Requirement already satisfied: grpcio-reflection==1.31.0 in /home/jsteinbauer/.local/lib/python3.8/site-packages (from ondewo-s2t-client==1.4.1) (1.31.0)\n",
      "Requirement already satisfied: grpcio-tools==1.31.0 in /home/jsteinbauer/.local/lib/python3.8/site-packages (from ondewo-s2t-client==1.4.1) (1.31.0)\n",
      "Requirement already satisfied: mypy-protobuf==1.20 in /home/jsteinbauer/.local/lib/python3.8/site-packages (from ondewo-s2t-client==1.4.1) (1.20)\n",
      "Requirement already satisfied: ondewo-client-utils>=0.1.0 in /home/jsteinbauer/.local/lib/python3.8/site-packages (from ondewo-s2t-client==1.4.1) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5.2 in /usr/local/Miniconda3-py38_4.8.3-Linux-x86_64/lib/python3.8/site-packages (from grpcio==1.31.0->ondewo-s2t-client==1.4.1) (1.15.0)\n",
      "Collecting protobuf>=3.6.0\n",
      "  Using cached protobuf-3.19.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Requirement already satisfied: regex==2020.7.14 in /home/jsteinbauer/.local/lib/python3.8/site-packages (from ondewo-client-utils>=0.1.0->ondewo-s2t-client==1.4.1) (2020.7.14)\n",
      "Requirement already satisfied: dataclasses-json==0.5.2 in /home/jsteinbauer/.local/lib/python3.8/site-packages (from ondewo-client-utils>=0.1.0->ondewo-s2t-client==1.4.1) (0.5.2)\n",
      "Requirement already satisfied: stringcase<2.0.0,==1.2.0 in /home/jsteinbauer/.local/lib/python3.8/site-packages (from dataclasses-json==0.5.2->ondewo-client-utils>=0.1.0->ondewo-s2t-client==1.4.1) (1.2.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/jsteinbauer/.local/lib/python3.8/site-packages (from dataclasses-json==0.5.2->ondewo-client-utils>=0.1.0->ondewo-s2t-client==1.4.1) (1.5.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/jsteinbauer/.local/lib/python3.8/site-packages (from dataclasses-json==0.5.2->ondewo-client-utils>=0.1.0->ondewo-s2t-client==1.4.1) (3.14.0)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/jsteinbauer/.local/lib/python3.8/site-packages (from dataclasses-json==0.5.2->ondewo-client-utils>=0.1.0->ondewo-s2t-client==1.4.1) (0.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/jsteinbauer/.local/lib/python3.8/site-packages (from typing-inspect>=0.4.0->dataclasses-json==0.5.2->ondewo-client-utils>=0.1.0->ondewo-s2t-client==1.4.1) (3.10.0.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/jsteinbauer/.local/lib/python3.8/site-packages (from typing-inspect>=0.4.0->dataclasses-json==0.5.2->ondewo-client-utils>=0.1.0->ondewo-s2t-client==1.4.1) (0.4.3)\n",
      "Building wheels for collected packages: ondewo-s2t-client\n",
      "  Building wheel for ondewo-s2t-client (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ondewo-s2t-client: filename=ondewo_s2t_client-1.4.1-py2.py3-none-any.whl size=20204 sha256=c714c1faea03e3a851f0ab02da82ecf9dc2d14d721fd1260bc12cfb70a078863\n",
      "  Stored in directory: /home/jsteinbauer/.cache/pip/wheels/68/33/5c/6741336a8de21fa9ea1d4ff5e96fc434fb52c5c39721dc69c7\n",
      "Successfully built ondewo-s2t-client\n",
      "Installing collected packages: ondewo-s2t-client, protobuf\n",
      "  Attempting uninstall: ondewo-s2t-client\n",
      "    Found existing installation: ondewo-s2t-client 1.4.1\n",
      "    Uninstalling ondewo-s2t-client-1.4.1:\n",
      "      Successfully uninstalled ondewo-s2t-client-1.4.1\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorboard 2.7.0 requires numpy>=1.12.0, which is not installed.\n",
      "pytorch-lightning 1.2.10 requires future>=0.17.1, which is not installed.\n",
      "pytorch-lightning 1.2.10 requires numpy>=1.16.6, which is not installed.\n",
      "pyannote-audio 1.1.1 requires librosa>=0.8.0, which is not installed.\n",
      "pyannote-audio 1.1.1 requires scikit-learn>=0.20.2, which is not installed.\n",
      "onnx 1.10.2 requires numpy>=1.16.6, which is not installed.\n",
      "nemo-toolkit 1.0.2 requires numpy>=1.18.2, which is not installed.\n",
      "nemo-toolkit 1.0.2 requires omegaconf<2.1.0,>=2.0.5, which is not installed.\n",
      "nemo-toolkit 1.0.2 requires scikit-learn, which is not installed.\n",
      "nemo-toolkit 1.0.2 requires transformers>=4.0.1, which is not installed.\n",
      "ondewo-nlu-client 2.1.0 requires protobuf==3.18.0, but you'll have protobuf 3.19.1 which is incompatible.\u001b[0m\n",
      "Successfully installed ondewo-s2t-client-1.4.1 protobuf-3.19.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "! cd .. && python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1634234935903,
     "user": {
      "displayName": "Andreas Rath",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjzXdeqp2hxSIMkaDT5PP1Srh8ARQRU8xQsUZeo=s64",
      "userId": "17066140692478356993"
     },
     "user_tz": -120
    },
    "id": "bcff103f"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import wave\n",
    "\n",
    "from ondewo.s2t import speech_to_text_pb2\n",
    "from ondewo.s2t.client.client import Client\n",
    "from ondewo.s2t.client.client_config import ClientConfig\n",
    "from ondewo.s2t.client.services.speech_to_text import Speech2Text\n",
    "from ondewo.s2t.speech_to_text_pb2 import ListS2tPipelinesRequest, Speech2TextConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a client object\n",
    "The example below shows how to create a speech to text client object from a client config. \n",
    "When setting *use_secure_channel=True*, a grpc certificate *grpc_cert* is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1634234935904,
     "user": {
      "displayName": "Andreas Rath",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjzXdeqp2hxSIMkaDT5PP1Srh8ARQRU8xQsUZeo=s64",
      "userId": "17066140692478356993"
     },
     "user_tz": -120
    },
    "id": "585c9e11",
    "outputId": "a032016c-49e1-46c3-bdb9-0187ce8fe72c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Using insecure grpc channel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClientConfig(host='localhost', port='50655', grpc_cert=None)\n"
     ]
    }
   ],
   "source": [
    "AUDIO_FILE: str = \"examples/audiofiles/sample_1.wav\"\n",
    "# credentials = grpc.ssl_channel_credentials(root_certificates=cert)\n",
    "\n",
    "MAX_MESSAGE_LENGTH: int = 60000000\n",
    "GRPC_HOST: str = \"localhost\" #\"<ADD GRPC SERVER HERE>\"\n",
    "GRPC_PORT: str = \"50655\" #\"<ADD GRPC PORT HERE>\"\n",
    "CHANNEL: str = f\"{GRPC_HOST}:{GRPC_PORT}\"\n",
    "grpc_cert: str = None #\"<ADD CERTIFICATE HERE>\"\n",
    "\n",
    "\n",
    "options = [\n",
    "    ('grpc.max_send_message_length', MAX_MESSAGE_LENGTH),\n",
    "    ('grpc.max_receive_message_length', MAX_MESSAGE_LENGTH),\n",
    "]\n",
    "\n",
    "# channel = grpc.secure_channel(CHANNEL, credentials, options=options)\n",
    "\n",
    "config: ClientConfig = ClientConfig(\n",
    "  host=GRPC_HOST,\n",
    "  port=GRPC_PORT, \n",
    "  grpc_cert=grpc_cert)\n",
    "    \n",
    "print(config)\n",
    "    \n",
    "client: Client = Client(config=config, use_secure_channel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List all existing speech to text pipelines\n",
    "All relevant configurations of the speech to text server are defined in a speech to text pipeline. \n",
    "A running server can store several such configs at the same time, such that the client can chose which one to \n",
    "pick when he sends a request to transcribe an audio file or stream.\n",
    "\n",
    "The example below shows how to list all available pipelines by calling the **s2t_service.list_s2t_pipelines()** function, which takes a **ListS2tPipelinesRequest()** as an argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 841,
     "status": "ok",
     "timestamp": 1634234936728,
     "user": {
      "displayName": "Andreas Rath",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjzXdeqp2hxSIMkaDT5PP1Srh8ARQRU8xQsUZeo=s64",
      "userId": "17066140692478356993"
     },
     "user_tz": -120
    },
    "id": "PT_wyVxIU8mk",
    "outputId": "72821027-e8c1-4732-d39a-383c78c20ec1",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: \"quarznet_en\"\n",
      "description {\n",
      "  language: \"en\"\n",
      "  pipeline_owner: \"ONDEWO\"\n",
      "  domain: \"general\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"quartznet\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/model_configs/en/quartznet15x5.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/en/quartznet15x5/\"\n",
      "        step: \"247400\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/de/ckpt_test/test.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/en/quartznet15x5.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec/wav2vec2-base-960h\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/ngram_lm_models/test/en/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"en_small\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    transcribe_not_final: true\n",
      "    ctc_decoding_method: \"GREEDY\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 1.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  pipeline: \"normalization\"\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/en-80k.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 2\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"english\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"quartznet_de\"\n",
      "description {\n",
      "  language: \"de\"\n",
      "  pipeline_owner: \"ONDEWO\"\n",
      "  domain: \"general\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"quartznet\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet15x5_de_2/\"\n",
      "        step: \"5000\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/de/ckpt_test/test.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec/wav2vec2-base-960h\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/ngram_lm_models/test/de/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"de_small\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    transcribe_not_final: true\n",
      "    ctc_decoding_method: \"BEAM_SEARCH_WITH_LM\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 1.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  pipeline: \"normalization\"\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 2\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"wav2vec_en\"\n",
      "description {\n",
      "  language: \"en\"\n",
      "  pipeline_owner: \"ONDEWO\"\n",
      "  domain: \"general\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"wav2vec\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/model_configs/en/quartznet15x5.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/en/quartznet15x5/\"\n",
      "        step: \"247400\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/de/ckpt_test/test.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/en/quartznet15x5.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec/wav2vec2-base-960h\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/ngram_lm_models/test/en/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"en_small\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    transcribe_not_final: true\n",
      "    ctc_decoding_method: \"GREEDY\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 1.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  pipeline: \"normalization\"\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/en-80k.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 2\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"english\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s2t_service: Speech2Text = client.services.speech_to_text\n",
    "pipelines = s2t_service.list_s2t_pipelines(request=ListS2tPipelinesRequest()).pipeline_configs\n",
    "for pipeline in pipelines:\n",
    "    print(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1634234936729,
     "user": {
      "displayName": "Andreas Rath",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjzXdeqp2hxSIMkaDT5PP1Srh8ARQRU8xQsUZeo=s64",
      "userId": "17066140692478356993"
     },
     "user_tz": -120
    },
    "id": "6ae3dc8d"
   },
   "outputs": [],
   "source": [
    "import wave \n",
    "with wave.open(\"audiofiles/sample_1.wav\") as w:\n",
    "    audio: bytes = w.readframes(w.getnframes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1634234936731,
     "user": {
      "displayName": "Andreas Rath",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjzXdeqp2hxSIMkaDT5PP1Srh8ARQRU8xQsUZeo=s64",
      "userId": "17066140692478356993"
     },
     "user_tz": -120
    },
    "id": "IEMZ_gzlW4nK"
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "def find_pipeline_for_language(pipelines: List[Speech2TextConfig], language: str) -> Optional[Speech2TextConfig]:\n",
    "    \"\"\" \n",
    "    Returns the first speech to text pipeline for the requested language. \n",
    "    If no pipline is found, return None.\n",
    "    \"\"\"\n",
    "    for pipeline in pipelines:\n",
    "        if pipeline.description.language == language:\n",
    "            return pipeline\n",
    "\n",
    "english_pipeline = find_pipeline_for_language(pipelines=pipelines, language='en')\n",
    "german_pipeline = find_pipeline_for_language(pipelines=pipelines, language='de')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a transcribe file request to the server\n",
    "In general, are two different endpoints for audio transcriptions:\n",
    "1. **Transcribe an audio file** \n",
    "2. **Transcribe an audio stream**\n",
    "\n",
    "In this example, we create a **TranscribeFileRequest**, including the audio file (as bytes) and a **TranscribeRequestConfig** message, including the speech to text pipeline id, as well as optional additional parameters.\n",
    "The request message is then used as an argument to the **s2t_service.transcribe_file()**, which calls the corresponding endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1055,
     "status": "ok",
     "timestamp": 1634234937777,
     "user": {
      "displayName": "Andreas Rath",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjzXdeqp2hxSIMkaDT5PP1Srh8ARQRU8xQsUZeo=s64",
      "userId": "17066140692478356993"
     },
     "user_tz": -120
    },
    "id": "34fe77f3",
    "outputId": "7221e03d-d89c-457d-a1f8-530c502302f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File transcript: der erste der januar siebzehnte sechste \n"
     ]
    }
   ],
   "source": [
    "pipeline: Speech2TextConfig = pipelines[1]\n",
    "\n",
    "request = speech_to_text_pb2.TranscribeFileRequest(\n",
    "    audio_file=audio,\n",
    "    config=speech_to_text_pb2.TranscribeRequestConfig(\n",
    "        s2t_pipeline_id=pipeline.id,\n",
    "        ctc_decoding=speech_to_text_pb2.CTCDecoding.BEAM_SEARCH_WITH_LM,\n",
    "    )\n",
    ")\n",
    "# Send transcription request and get response\n",
    "transcribe_response = s2t_service.transcribe_file(request=request)\n",
    "\n",
    "for transcription_message in transcribe_response.transcriptions:\n",
    "    print(f\"File transcript: {transcription_message.transcription}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ondewo-s2t-with-certificate.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "de2ed104cf3bee5ac5c3780eed171797f09568a0a669428569335bd376aa9e40"
  },
  "kernelspec": {
   "display_name": "ondewo_s2t_client",
   "language": "python",
   "name": "ondewo_s2t_client"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
