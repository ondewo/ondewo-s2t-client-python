{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Processing /home/jsteinbauer/ondewo/ondewo-s2t-client-python\n",
      "Collecting grpcio==1.42.0\n",
      "  Downloading grpcio-1.42.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio-reflection==1.42.0\n",
      "  Downloading grpcio_reflection-1.42.0-py3-none-any.whl (15 kB)\n",
      "Collecting grpcio-tools==1.42.0\n",
      "  Downloading grpcio_tools-1.42.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mypy-protobuf==3.00\n",
      "  Downloading mypy_protobuf-3.0.0-py3-none-any.whl (15 kB)\n",
      "Collecting ondewo-client-utils>=0.1.0\n",
      "  Downloading ondewo_client_utils-0.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: six>=1.5.2 in /usr/local/Miniconda3-py38_4.8.3-Linux-x86_64/lib/python3.8/site-packages (from grpcio==1.42.0->ondewo-s2t-client==3.1.1) (1.15.0)\n",
      "Collecting protobuf>=3.6.0\n",
      "  Downloading protobuf-3.20.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/Miniconda3-py38_4.8.3-Linux-x86_64/lib/python3.8/site-packages (from grpcio-tools==1.42.0->ondewo-s2t-client==3.1.1) (49.6.0.post20200814)\n",
      "Collecting types-protobuf>=3.17.4\n",
      "  Downloading types_protobuf-3.19.15-py3-none-any.whl (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dataclasses-json==0.5.2\n",
      "  Downloading dataclasses_json-0.5.2-py3-none-any.whl (23 kB)\n",
      "Collecting regex==2020.7.14\n",
      "  Downloading regex-2020.7.14-cp38-cp38-manylinux2010_x86_64.whl (672 kB)\n",
      "\u001b[K     |████████████████████████████████| 672 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting marshmallow<4.0.0,>=3.3.0\n",
      "  Downloading marshmallow-3.15.0-py3-none-any.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1\n",
      "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting stringcase<2.0.0,==1.2.0\n",
      "  Downloading stringcase-1.2.0.tar.gz (3.0 kB)\n",
      "Collecting typing-inspect>=0.4.0\n",
      "  Downloading typing_inspect-0.7.1-py3-none-any.whl (8.4 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/Miniconda3-py38_4.8.3-Linux-x86_64/lib/python3.8/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json==0.5.2->ondewo-client-utils>=0.1.0->ondewo-s2t-client==3.1.1) (20.4)\n",
      "Collecting typing-extensions>=3.7.4\n",
      "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/Miniconda3-py38_4.8.3-Linux-x86_64/lib/python3.8/site-packages (from packaging->marshmallow<4.0.0,>=3.3.0->dataclasses-json==0.5.2->ondewo-client-utils>=0.1.0->ondewo-s2t-client==3.1.1) (2.4.7)\n",
      "Building wheels for collected packages: ondewo-s2t-client, stringcase\n",
      "  Building wheel for ondewo-s2t-client (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ondewo-s2t-client: filename=ondewo_s2t_client-3.1.1-py2.py3-none-any.whl size=20316 sha256=723ef23191416ac9848415e4ef67a2cacc5c644f0ebb00bb313d7a7bd5caabf1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4b0p8zgl/wheels/68/33/5c/6741336a8de21fa9ea1d4ff5e96fc434fb52c5c39721dc69c7\n",
      "  Building wheel for stringcase (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for stringcase: filename=stringcase-1.2.0-py3-none-any.whl size=3576 sha256=11890504587d0b0c560f4aa2f935d44c272a7ce09168d752fae982cbfa7c14ef\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4b0p8zgl/wheels/04/0e/31/bf265c64f2a4d24516e9923f1f6293c3bcbcde75e0d80ab47a\n",
      "Successfully built ondewo-s2t-client stringcase\n",
      "Installing collected packages: grpcio, protobuf, grpcio-reflection, grpcio-tools, types-protobuf, mypy-protobuf, marshmallow, marshmallow-enum, stringcase, typing-extensions, mypy-extensions, typing-inspect, dataclasses-json, regex, ondewo-client-utils, ondewo-s2t-client\n",
      "Successfully installed dataclasses-json-0.5.2 grpcio-1.42.0 grpcio-reflection-1.42.0 grpcio-tools-1.42.0 marshmallow-3.15.0 marshmallow-enum-1.5.1 mypy-extensions-0.4.3 mypy-protobuf-3.0.0 ondewo-client-utils-0.1.0 ondewo-s2t-client-3.1.1 protobuf-3.20.0 regex-2020.7.14 stringcase-1.2.0 types-protobuf-3.19.15 typing-extensions-4.1.1 typing-inspect-0.7.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "! cd .. && python -m pip install --user ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1634234935903,
     "user": {
      "displayName": "Andreas Rath",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjzXdeqp2hxSIMkaDT5PP1Srh8ARQRU8xQsUZeo=s64",
      "userId": "17066140692478356993"
     },
     "user_tz": -120
    },
    "id": "bcff103f"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import wave\n",
    "\n",
    "from ondewo.s2t import speech_to_text_pb2\n",
    "from ondewo.s2t.client.client import Client\n",
    "from ondewo.s2t.client.client_config import ClientConfig\n",
    "from ondewo.s2t.client.services.speech_to_text import Speech2Text\n",
    "from ondewo.s2t.speech_to_text_pb2 import ListS2tPipelinesRequest, Speech2TextConfig\n",
    "from ondewo.s2t.speech_to_text_pb2 import S2tPipelineId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a client object\n",
    "The example below shows how to create a speech to text client object from a client config. \n",
    "When setting *use_secure_channel=True*, a grpc certificate *grpc_cert* is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1634234935904,
     "user": {
      "displayName": "Andreas Rath",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjzXdeqp2hxSIMkaDT5PP1Srh8ARQRU8xQsUZeo=s64",
      "userId": "17066140692478356993"
     },
     "user_tz": -120
    },
    "id": "585c9e11",
    "outputId": "a032016c-49e1-46c3-bdb9-0187ce8fe72c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Using insecure grpc channel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClientConfig(host='dgxstation', port='50658', grpc_cert=None)\n"
     ]
    }
   ],
   "source": [
    "AUDIO_FILE: str = \"examples/audiofiles/sample_1.wav\"\n",
    "# credentials = grpc.ssl_channel_credentials(root_certificates=cert)\n",
    "\n",
    "MAX_MESSAGE_LENGTH: int = 60000000\n",
    "GRPC_HOST: str = \"dgxstation\"\n",
    "GRPC_PORT: str = \"50658\"\n",
    "CHANNEL: str = f\"{GRPC_HOST}:{GRPC_PORT}\"\n",
    "grpc_cert: str = None\n",
    "\n",
    "\n",
    "options = [\n",
    "    ('grpc.max_send_message_length', MAX_MESSAGE_LENGTH),\n",
    "    ('grpc.max_receive_message_length', MAX_MESSAGE_LENGTH),\n",
    "]\n",
    "\n",
    "# channel = grpc.secure_channel(CHANNEL, credentials, options=options)\n",
    "\n",
    "config: ClientConfig = ClientConfig(\n",
    "  host=GRPC_HOST,\n",
    "  port=GRPC_PORT, \n",
    "  grpc_cert=grpc_cert)\n",
    "    \n",
    "print(config)\n",
    "    \n",
    "client: Client = Client(config=config, use_secure_channel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List all existing speech to text pipelines\n",
    "All relevant configurations of the speech to text server are defined in a speech to text pipeline. \n",
    "A running server can store several such configs at the same time, such that the client can chose which one to \n",
    "pick when he sends a request to transcribe an audio file or stream.\n",
    "\n",
    "The example below shows how to list all available pipelines by calling the **s2t_service.list_s2t_pipelines()** function, which takes a **ListS2tPipelinesRequest()** as an argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 841,
     "status": "ok",
     "timestamp": 1634234936728,
     "user": {
      "displayName": "Andreas Rath",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjzXdeqp2hxSIMkaDT5PP1Srh8ARQRU8xQsUZeo=s64",
      "userId": "17066140692478356993"
     },
     "user_tz": -120
    },
    "id": "PT_wyVxIU8mk",
    "outputId": "72821027-e8c1-4732-d39a-383c78c20ec1",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: \"gwt001\"\n",
      "description {\n",
      "  language: \"de\"\n",
      "  pipeline_owner: \"ondewo\"\n",
      "  domain: \"logistics\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"quartznet\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/de/quartznet_telephone/quartznet_telephone.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet_telephone/\"\n",
      "        step: \"2500\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/de/ckpt_test/test.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/gwt/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"gwt.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"BEAM_SEARCH_WITH_LM\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 60.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  pipeline: \"normalization\"\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"ato001_old\"\n",
      "description {\n",
      "  language: \"de\"\n",
      "  pipeline_owner: \"ondewo\"\n",
      "  domain: \"itsupport\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"quartznet\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/de/quartznet_telephone/quartznet_telephone.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet_telephone/\"\n",
      "        step: \"2500\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/de/ckpt_test/test.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"atos.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"BEAM_SEARCH_WITH_LM\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 60.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  pipeline: \"normalization\"\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"general_english\"\n",
      "description {\n",
      "  language: \"en\"\n",
      "  pipeline_owner: \"ONDEWO\"\n",
      "  domain: \"general\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"wav2vec\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet15x5_de_2/\"\n",
      "        step: \"837000\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/en/quartznet_czech_atc/QuartzNet15x5_czech_atc-last.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec_large_960h_lv60_self\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"all_atc.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"GREEDY\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 30.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 2\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"elo001VAD13\"\n",
      "description {\n",
      "  language: \"de\"\n",
      "  pipeline_owner: \"eloqai\"\n",
      "  domain: \"medical\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"quartznet\"\n",
      "    quartznet {\n",
      "      config_path: \"models/eloqai/de-AT/radiology001/0.0.1/acoustic_model/quartznet_de.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"models/eloqai/de-AT/radiology001/0.0.1/acoustic_model/\"\n",
      "        step: \"2500\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/de/ckpt_test/test.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"models/eloqai/de-AT/radiology001/0.0.1/acoustic_model/quartznet_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"models/eloqai/de-AT/radiology001/0.0.1/language_model/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"kenlm_eloqai_2.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"BEAM_SEARCH_WITH_LM\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 1.2999999523162842\n",
      "    next_chunk_timeout: 60.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"models/eloqai/de-AT/radiology001/0.0.1/vad_model/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  pipeline: \"normalization\"\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"keb001\"\n",
      "description {\n",
      "  language: \"de\"\n",
      "  pipeline_owner: \"ondewo\"\n",
      "  domain: \"robotics\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"wav2vec\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/de/quartznet_telephone/quartznet_telephone.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet_telephone/\"\n",
      "        step: \"2500\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/de/ckpt_test/test.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/wav2vec2_large_1360h_telephonized/\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"keba.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"BEAM_SEARCH_WITH_LM\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 60.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  pipeline: \"normalization\"\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"wav2vec_base_all_atc\"\n",
      "description {\n",
      "  language: \"en\"\n",
      "  pipeline_owner: \"ONDEWO\"\n",
      "  domain: \"atc\"\n",
      "}\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"wav2vec\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet15x5_de_2/\"\n",
      "        step: \"837000\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/en/quartznet_czech_atc/QuartzNet15x5_czech_atc-last.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec_base_all_atc\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"all_atc.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"GREEDY\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 30.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"ato001\"\n",
      "description {\n",
      "  language: \"de\"\n",
      "  pipeline_owner: \"ondewo\"\n",
      "  domain: \"itsupport\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"wav2vec\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/de/quartznet_telephone/quartznet_telephone.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet_telephone/\"\n",
      "        step: \"2500\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/de/ckpt_test/test.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/wav2vec2_large_1360h_telephonized/\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"german_lm_big.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"BEAM_SEARCH_WITH_LM\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 60.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  pipeline: \"normalization\"\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"elo001VAD17\"\n",
      "description {\n",
      "  language: \"de\"\n",
      "  pipeline_owner: \"eloqai\"\n",
      "  domain: \"medical\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"quartznet\"\n",
      "    quartznet {\n",
      "      config_path: \"models/eloqai/de-AT/radiology001/0.0.1/acoustic_model/quartznet_de.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"models/eloqai/de-AT/radiology001/0.0.1/acoustic_model/\"\n",
      "        step: \"2500\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/de/ckpt_test/test.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"models/eloqai/de-AT/radiology001/0.0.1/acoustic_model/quartznet_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"models/eloqai/de-AT/radiology001/0.0.1/language_model/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"kenlm_eloqai_2.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"BEAM_SEARCH_WITH_LM\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 1.7000000476837158\n",
      "    next_chunk_timeout: 60.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"models/eloqai/de-AT/radiology001/0.0.1/vad_model/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  pipeline: \"normalization\"\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"elo001VAD1\"\n",
      "description {\n",
      "  language: \"de\"\n",
      "  pipeline_owner: \"eloqai\"\n",
      "  domain: \"medical\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"quartznet\"\n",
      "    quartznet {\n",
      "      config_path: \"models/eloqai/de-AT/radiology001/0.0.1/acoustic_model/quartznet_de.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"models/eloqai/de-AT/radiology001/0.0.1/acoustic_model/\"\n",
      "        step: \"2500\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/de/ckpt_test/test.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"models/eloqai/de-AT/radiology001/0.0.1/acoustic_model/quartznet_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"models/eloqai/de-AT/radiology001/0.0.1/language_model/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"kenlm_eloqai_2.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"BEAM_SEARCH_WITH_LM\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 1.0\n",
      "    next_chunk_timeout: 60.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"models/eloqai/de-AT/radiology001/0.0.1/vad_model/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  pipeline: \"normalization\"\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"wav2vec_base_cz_atc\"\n",
      "description {\n",
      "  language: \"en\"\n",
      "  pipeline_owner: \"ONDEWO\"\n",
      "  domain: \"atc\"\n",
      "}\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"wav2vec\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet15x5_de_2/\"\n",
      "        step: \"837000\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/en/quartznet_czech_atc/QuartzNet15x5_czech_atc-last.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec_base_cz_atc\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"all_atc.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"GREEDY\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 30.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"elo001\"\n",
      "description {\n",
      "  language: \"de\"\n",
      "  pipeline_owner: \"eloqai\"\n",
      "  domain: \"medical\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"quartznet\"\n",
      "    quartznet {\n",
      "      config_path: \"models/eloqai/de-AT/radiology001/0.0.1/acoustic_model/quartznet_de.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"models/eloqai/de-AT/radiology001/0.0.1/acoustic_model/\"\n",
      "        step: \"2500\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/de/ckpt_test/test.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"models/eloqai/de-AT/radiology001/0.0.1/acoustic_model/quartznet_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"models/eloqai/de-AT/radiology001/0.0.1/language_model/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"kenlm_eloqai_2\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"BEAM_SEARCH_WITH_LM\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 60.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"models/eloqai/de-AT/radiology001/0.0.1/vad_model/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  pipeline: \"normalization\"\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"elo001VAD15\"\n",
      "description {\n",
      "  language: \"de\"\n",
      "  pipeline_owner: \"eloqai\"\n",
      "  domain: \"medical\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"quartznet\"\n",
      "    quartznet {\n",
      "      config_path: \"models/eloqai/de-AT/radiology001/0.0.1/acoustic_model/quartznet_de.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"models/eloqai/de-AT/radiology001/0.0.1/acoustic_model/\"\n",
      "        step: \"2500\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/de/ckpt_test/test.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"models/eloqai/de-AT/radiology001/0.0.1/acoustic_model/quartznet_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"models/eloqai/de-AT/radiology001/0.0.1/language_model/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"kenlm_eloqai_2.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"BEAM_SEARCH_WITH_LM\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 1.5\n",
      "    next_chunk_timeout: 60.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"models/eloqai/de-AT/radiology001/0.0.1/vad_model/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  pipeline: \"normalization\"\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"wav2vec_large_czech_atc_augmented\"\n",
      "description {\n",
      "  language: \"en\"\n",
      "  pipeline_owner: \"ONDEWO\"\n",
      "  domain: \"atc\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"wav2vec\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet15x5_de_2/\"\n",
      "        step: \"837000\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/en/quartznet_czech_atc/QuartzNet15x5_czech_atc-last.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec_large_cz_atc_augmented\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"all_atc.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"GREEDY\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 30.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"wav2vec_large_all_atc\"\n",
      "description {\n",
      "  language: \"en\"\n",
      "  pipeline_owner: \"ONDEWO\"\n",
      "  domain: \"atc\"\n",
      "}\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"wav2vec\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet15x5_de_2/\"\n",
      "        step: \"837000\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/en/quartznet_czech_atc/QuartzNet15x5_czech_atc-last.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec_large_all_atc\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"all_atc.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"GREEDY\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 30.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"wav2vec_large_cz_atc\"\n",
      "description {\n",
      "  language: \"en\"\n",
      "  pipeline_owner: \"ONDEWO\"\n",
      "  domain: \"atc\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"wav2vec\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet15x5_de_2/\"\n",
      "        step: \"837000\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/en/quartznet_czech_atc/QuartzNet15x5_czech_atc-last.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec_large_cz_atc\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"all_atc.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"GREEDY\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 30.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"survey\"\n",
      "description {\n",
      "  language: \"de\"\n",
      "  pipeline_owner: \"ONDEWO\"\n",
      "  domain: \"survey\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"quartznet\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/de/quartznet_telephone/quartznet_telephone.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet_telephone/\"\n",
      "        step: \"2500\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/de/ckpt_test/test.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/survey/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"survey.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"BEAM_SEARCH_WITH_LM\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.10000000149011612\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 60.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  pipeline: \"normalization\"\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"tir002\"\n",
      "description {\n",
      "  language: \"de\"\n",
      "  pipeline_owner: \"ondewo\"\n",
      "  domain: \"logistics\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"quartznet\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/de/quartznet_telephone/quartznet_telephone.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet_telephone/\"\n",
      "        step: \"2500\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/de/ckpt_test/test.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/tirolia/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"tirolia.binary\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"BEAM_SEARCH_WITH_LM\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.10000000149011612\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 60.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  pipeline: \"normalization\"\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"german_general\"\n",
      "description {\n",
      "  language: \"de\"\n",
      "  pipeline_owner: \"ONDEWO\"\n",
      "  domain: \"general\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"quartznet\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/de/quartznet_telephone/quartznet_telephone.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet_telephone/\"\n",
      "        step: \"2500\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/de/ckpt_test/test.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"german_lm_big\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    ctc_decoding_method: \"BEAM_SEARCH_WITH_LM\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 60.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  pipeline: \"normalization\"\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "id: \"default_german\"\n",
      "description {\n",
      "  language: \"de\"\n",
      "  pipeline_owner: \"ONDEWO\"\n",
      "  domain: \"general\"\n",
      "}\n",
      "active: true\n",
      "inference {\n",
      "  ctc_acoustic_models {\n",
      "    type: \"quartznet\"\n",
      "    quartznet {\n",
      "      config_path: \"acoustic_models/de/quartznet_telephone/quartznet_telephone.yaml\"\n",
      "      load_type: \"pt_files\"\n",
      "      pt_files {\n",
      "        path: \"acoustic_models/de/quartznet_telephone/\"\n",
      "        step: \"2500\"\n",
      "      }\n",
      "      ckpt_file {\n",
      "        path: \"acoustic_models/de/ckpt_test/test.ckpt\"\n",
      "      }\n",
      "      use_gpu: true\n",
      "    }\n",
      "    quartznet_triton {\n",
      "      config_path: \"acoustic_models/model_configs/de/quartznet15x5_de.yaml\"\n",
      "      triton_url: \"localhost:8001\"\n",
      "      triton_model: \"quartznet\"\n",
      "    }\n",
      "    wav2vec {\n",
      "      model_path: \"acoustic_models/en/wav2vec\"\n",
      "      use_gpu: true\n",
      "    }\n",
      "  }\n",
      "  language_models {\n",
      "    path: \"language_models/\"\n",
      "    beam_size: 64\n",
      "    default_lm: \"german_lm_big\"\n",
      "    beam_search_scorer_alpha: 2.0\n",
      "    beam_search_scorer_beta: 1.0\n",
      "  }\n",
      "}\n",
      "streaming_server {\n",
      "  output_style: \"simple\"\n",
      "  streaming_speech_recognition {\n",
      "    transcribe_not_final: true\n",
      "    ctc_decoding_method: \"GREEDY\"\n",
      "    sampling_rate: 16000\n",
      "    min_audio_chunk_size: 8000\n",
      "    start_of_utterance_threshold: 0.25\n",
      "    end_of_utterance_threshold: 0.75\n",
      "    next_chunk_timeout: 60.0\n",
      "  }\n",
      "}\n",
      "voice_activity_detection {\n",
      "  active: \"pyannote\"\n",
      "  sampling_rate: 16000\n",
      "  pyannote {\n",
      "    model_path: \"vad_models/pyannote/model/train/other/validate\"\n",
      "    min_audio_size: 8000\n",
      "    offset: 0.8500000238418579\n",
      "    onset: 0.8500000238418579\n",
      "    log_scale: true\n",
      "    min_duration_off: 0.009999999776482582\n",
      "    min_duration_on: 0.009999999776482582\n",
      "  }\n",
      "  matchbox {\n",
      "    model_config: \"vad_models/matchbox/matchbox_config.yaml\"\n",
      "    encoder_path: \"vad_models/matchbox/matchbox_encoder.pt\"\n",
      "    decoder_path: \"vad_models/matchbox/matchbox_decoder.pt\"\n",
      "  }\n",
      "}\n",
      "post_processing {\n",
      "  pipeline: \"normalization\"\n",
      "  post_processors {\n",
      "    sym_spell {\n",
      "      dict_path: \"server_assets/spelling_dicts/de_full.txt\"\n",
      "      max_dictionary_edit_distance: 2\n",
      "      prefix_length: 7\n",
      "    }\n",
      "    normalization {\n",
      "      language: \"german\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s2t_service: Speech2Text = client.services.speech_to_text\n",
    "pipelines = s2t_service.list_s2t_pipelines(request=ListS2tPipelinesRequest()).pipeline_configs\n",
    "for pipeline in pipelines:\n",
    "    print(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1634234936731,
     "user": {
      "displayName": "Andreas Rath",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjzXdeqp2hxSIMkaDT5PP1Srh8ARQRU8xQsUZeo=s64",
      "userId": "17066140692478356993"
     },
     "user_tz": -120
    },
    "id": "IEMZ_gzlW4nK"
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "def find_pipeline_for_language(pipelines: List[Speech2TextConfig], language: str) -> Optional[Speech2TextConfig]:\n",
    "    \"\"\" \n",
    "    Returns the first speech to text pipeline for the requested language. \n",
    "    If no pipline is found, return None.\n",
    "    \"\"\"\n",
    "    for pipeline in pipelines:\n",
    "        if pipeline.description.language == language:\n",
    "            return pipeline\n",
    "\n",
    "english_pipeline = find_pipeline_for_language(pipelines=pipelines, language='en')\n",
    "german_pipeline = find_pipeline_for_language(pipelines=pipelines, language='de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "general_english\n",
      "wav2vec_base_all_atc\n",
      "wav2vec_base_cz_atc\n",
      "wav2vec_large_czech_atc_augmented\n",
      "wav2vec_large_all_atc\n",
      "wav2vec_large_cz_atc\n"
     ]
    }
   ],
   "source": [
    "for pipeline in pipelines:\n",
    "    if pipeline.description.language == 'en':\n",
    "        print(pipeline.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in example audio file\n",
    "This audio file will be used in the following transcription examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave \n",
    "\n",
    "audio_file_path = \"audiofiles/sample_1.wav\"\n",
    "\n",
    "with wave.open(audio_file_path) as w:\n",
    "    audio: bytes = w.readframes(w.getnframes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a transcribe file request to the server\n",
    "In general, are two different endpoints for audio transcriptions:\n",
    "1. **Transcribe an audio file** \n",
    "2. **Transcribe an audio stream**\n",
    "\n",
    "### Transcribe an audio file\n",
    "In this example, we create a **TranscribeFileRequest**, including the audio file (as bytes) and a **TranscribeRequestConfig** message, including the speech to text pipeline id, as well as optional additional parameters.\n",
    "The request message is then used as an argument to the **s2t_service.transcribe_file()**, which calls the corresponding endpoint.\n",
    "\n",
    "### TranscribeRequestConfig\n",
    "The TranscribeRequestConfig gives you maximal control in configuring the s2t server. \n",
    "\n",
    "It contains the following fields:\n",
    "\n",
    "1. **s2t_pipeline_id** (string): The pipeline id\n",
    "2. **ctc_decoding** (speech_to_text_pb2.CTCDecoding): The CTC decoding type - options are BEAM_SEARCH_WITH_LM, GREEDY\n",
    "3. **language_model_name** (string): The name of the language model\n",
    "4. **post_processing** (speech_to_text_pb2.PostProcessingOptions): Specifies options for post processing\n",
    "5. **utterance_detection** (speech_to_text_pb2.UtteranceDetectionOptions)\n",
    "6. **voice_activity_detection**: One of speech_to_text_pb2.Pyannote or speech_to_text_pb2.Matchbox\n",
    "7. **return_options** (speech_to_text_pb2.TranscriptionReturnOptions): The options on how to return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1055,
     "status": "ok",
     "timestamp": 1634234937777,
     "user": {
      "displayName": "Andreas Rath",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjzXdeqp2hxSIMkaDT5PP1Srh8ARQRU8xQsUZeo=s64",
      "userId": "17066140692478356993"
     },
     "user_tz": -120
    },
    "id": "34fe77f3",
    "outputId": "7221e03d-d89c-457d-a1f8-530c502302f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File transcript: hello i would like to order one large bitza with ham and cheese no mushrooms please \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "pipeline: Speech2TextConfig = english_pipeline\n",
    "\n",
    "request = speech_to_text_pb2.TranscribeFileRequest(\n",
    "    audio_file=audio,\n",
    "    config=speech_to_text_pb2.TranscribeRequestConfig(\n",
    "        s2t_pipeline_id=pipeline.id,\n",
    "        ctc_decoding=speech_to_text_pb2.CTCDecoding.GREEDY,\n",
    "    )\n",
    ")\n",
    "# Send transcription request and get response\n",
    "transcribe_response = s2t_service.transcribe_file(request=request)\n",
    "\n",
    "for transcription_message in transcribe_response.transcriptions:\n",
    "    print(f\"File transcript: {transcription_message.transcription}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe an audio stream\n",
    "In this example, we transcribe an audio stream by streaming a **TranscribeStreamRequest**, including audio chunks (as bytes) and a **TranscribeRequestConfig** message, including the speech to text pipeline id, as well as optional additional parameters.\n",
    "The request message generator is then used as an argument to the **s2t_service.transcribe_stream()**, which calls the corresponding endpoint.\n",
    "\n",
    "**Important**: After the TranscribeRequestConfig has been set once, it does not have to be sent with each new streameing request (this can help to save bandwidth). The old TranscribeRequestConfig remains until a new one is sent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1.: Transcribe full utterances only (default)\n",
    "In this mode, audio chunks are concatenated until a full utterance is accumulated (an utterance is considered \"finished\" if no voice is detected in the audio signal for `end_of_utterance_threshold` seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "from streaming_example import get_streaming_audio, create_streaming_request\n",
    "\n",
    "# Get audio stream (iterator of audio chunks)\n",
    "audio_stream: Iterator[bytes] = get_streaming_audio(\"audiofiles/sample_1.wav\")\n",
    "\n",
    "# Create streaming request\n",
    "streaming_request: Iterator[speech_to_text_pb2.TranscribeStreamRequest] = create_streaming_request(\n",
    "    audio_stream=audio_stream, \n",
    "    pipeline_id=pipeline.id,\n",
    "    transcribe_not_final=False,\n",
    ")\n",
    "\n",
    "# Transcribe the stream and get back responses\n",
    "response_gen: Iterator[speech_to_text_pb2.TranscribeStreamResponse] = s2t_service.transcribe_stream(\n",
    "    request_iterator=streaming_request\n",
    ")\n",
    "\n",
    "# Print transcribed utterances\n",
    "for i, response_chunk in enumerate(response_gen):\n",
    "    for transcribe_message in response_chunk.transcriptions:\n",
    "        print(f\"{i}. response_chunk: {transcribe_message.transcription}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1.: Transcribe not final\n",
    "In this mode, audio chunks are transcribed as soon as a minimal length of voice signal is accumulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "from streaming_example import get_streaming_audio, create_streaming_request\n",
    "\n",
    "# Get audio stream (iterator of audio chunks)\n",
    "audio_stream: Iterator[bytes] = get_streaming_audio(\"audiofiles/sample_1.wav\")\n",
    "\n",
    "# Create streaming request\n",
    "streaming_request: Iterator[speech_to_text_pb2.TranscribeStreamRequest] = create_streaming_request(\n",
    "    audio_stream=audio_stream, \n",
    "    pipeline_id=pipeline.id, \n",
    "    transcribe_not_final=True,\n",
    ")\n",
    "\n",
    "# Transcribe the stream and get back responses\n",
    "response_gen: Iterator[speech_to_text_pb2.TranscribeStreamResponse] = s2t_service.transcribe_stream(\n",
    "    request_iterator=streaming_request\n",
    ")\n",
    "\n",
    "# Print transcribed utterances\n",
    "for i, response_chunk in enumerate(response_gen):\n",
    "    for transcribe_message in response_chunk.transcriptions:\n",
    "        print(f\"{i}. response_chunk: {transcribe_message.transcription}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline CRUD\n",
    "In the following, we demonstrate how to do CRUD (Create, Retrieve, Update, Delete) pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GetS2TPipeline\n",
    "\n",
    "The example below shows how to get a pipeline by calling the **s2t_service.get_s2t_pipeline()** function, which takes a **S2tPipelineId** as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### GetS2TPipeline\n",
    "# To get a specific s2t pipeline, we can use the GetS2TPipeline endpoint.\n",
    "\n",
    "pipeline_id = 'quarznet_en'\n",
    "pipeline = s2t_service.get_s2t_pipeline(request=S2tPipelineId(id=pipeline_id))\n",
    "\n",
    "pipelines = s2t_service.list_s2t_pipelines(request=ListS2tPipelinesRequest(registered_only=True)).pipeline_configs\n",
    "print(f\"Number of pipelines: {len(pipelines)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeleteS2TPipeline\n",
    "\n",
    "The example below shows how to delete a pipeline by calling the **s2t_service.delete_s2t_pipeline()** function, which takes a **S2tPipelineId** as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### DeleteS2TPipeline\n",
    "# To delete specific s2t pipeline, we can use the GetS2TPipeline endpoint.\n",
    "\n",
    "deleted_pipeline = s2t_service.delete_s2t_pipeline(request=S2tPipelineId(id=pipeline_id))\n",
    "\n",
    "pipelines = s2t_service.list_s2t_pipelines(request=ListS2tPipelinesRequest(registered_only=True)).pipeline_configs\n",
    "print(f\"Number of pipelines after pipeline deletion: {len(pipelines)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CreateS2TPipeline\n",
    "\n",
    "The example below shows how to create a pipeline by calling the **s2t_service.create_s2t_pipeline()** function, which takes a **pipeline** as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ### CreateS2TPipeline\n",
    "# # To create specific s2t pipeline, we can use the CreateS2TPipeline endpoint.\n",
    "\n",
    "pipeline = s2t_service.create_s2t_pipeline(request=pipeline)\n",
    "\n",
    "pipelines = s2t_service.list_s2t_pipelines(request=ListS2tPipelinesRequest(registered_only=True)).pipeline_configs\n",
    "print(f\"Number of pipelines after pipeline creation: {len(pipelines)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ### UpdateS2TPipeline\n",
    "# # To update specific s2t pipeline, we can use the UpdateS2TPipeline endpoint.\n",
    "\n",
    "pipeline_id = 'quarznet_en'\n",
    "pipeline = s2t_service.get_s2t_pipeline(request=S2tPipelineId(id=pipeline_id))\n",
    "\n",
    "print(f\"Old end_of_utterance_threshold: {pipeline.streaming_server.streaming_speech_recognition.end_of_utterance_threshold}\")\n",
    "\n",
    "# Update the end_of_utterance_threshold\n",
    "pipeline.streaming_server.streaming_speech_recognition.end_of_utterance_threshold = 1.5\n",
    "s2t_service.update_s2t_pipeline(request=pipeline)\n",
    "\n",
    "new_pipeline = s2t_service.get_s2t_pipeline(request=S2tPipelineId(id=pipeline_id))\n",
    "\n",
    "print(f\"New end_of_utterance_threshold: {new_pipeline.streaming_server.streaming_speech_recognition.end_of_utterance_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ondewo-s2t-with-certificate.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "de2ed104cf3bee5ac5c3780eed171797f09568a0a669428569335bd376aa9e40"
  },
  "kernelspec": {
   "display_name": "florian_env",
   "language": "python",
   "name": "florian_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
